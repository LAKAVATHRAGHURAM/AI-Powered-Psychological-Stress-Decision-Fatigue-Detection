{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d6733b5-8214-42b1-b7c1-db485a3d1c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b68d798-bc44-4ad4-a07a-470bd784a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset path\n",
    "DATASET_PATH = \"../data/speech_samples/1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "193588a2-5297-4378-a3aa-69d050e52f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_files(dataset_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    actors = os.listdir(dataset_path)\n",
    "    \n",
    "    for actor in actors:\n",
    "        actor_path = os.path.join(dataset_path, actor)\n",
    "        if os.path.isdir(actor_path):\n",
    "            for file in os.listdir(actor_path):\n",
    "                if file.endswith(\".wav\"):\n",
    "                    file_path = os.path.join(actor_path, file)\n",
    "                    signal, sr = librosa.load(file_path, sr=22050)\n",
    "                    mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13)\n",
    "                    mfccs = np.mean(mfccs, axis=1)  # Take mean across time axis\n",
    "                    \n",
    "                    data.append(mfccs)\n",
    "                    labels.append(actor)  # Using actor ID as a label for now\n",
    "    \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0705fc4-3655-408d-857b-23c72fbdbc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "X, y = load_audio_files(DATASET_PATH)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2f5c419-6aa6-4a52-9f76-58932e91eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../model/speech_label_encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48c849e-efcd-4a94-a28d-ca334bbe3048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2da0eb8-63c4-47e3-8117-793f72ea0a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(np.unique(y_encoded)), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65e4e4ef-3833-42da-b79d-f229bb0cfd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "084153c5-757b-4901-b8e6-ebc183af966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input data\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4afadcdd-0e52-46fa-8264-01ddf772fa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.0551 - loss: 3.0895 - val_accuracy: 0.0729 - val_loss: 2.8737\n",
      "Epoch 2/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0939 - loss: 2.8801 - val_accuracy: 0.1181 - val_loss: 2.6916\n",
      "Epoch 3/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1273 - loss: 2.7418 - val_accuracy: 0.1389 - val_loss: 2.6301\n",
      "Epoch 4/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1508 - loss: 2.6696 - val_accuracy: 0.1840 - val_loss: 2.5476\n",
      "Epoch 5/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.1730 - loss: 2.5577 - val_accuracy: 0.2292 - val_loss: 2.4946\n",
      "Epoch 6/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1982 - loss: 2.4753 - val_accuracy: 0.1875 - val_loss: 2.5070\n",
      "Epoch 7/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.2231 - loss: 2.4007 - val_accuracy: 0.2951 - val_loss: 2.3579\n",
      "Epoch 8/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.2657 - loss: 2.2879 - val_accuracy: 0.3194 - val_loss: 2.2358\n",
      "Epoch 9/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3136 - loss: 2.1053 - val_accuracy: 0.3021 - val_loss: 2.1578\n",
      "Epoch 10/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3419 - loss: 2.0537 - val_accuracy: 0.3611 - val_loss: 2.0705\n",
      "Epoch 11/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3750 - loss: 2.0031 - val_accuracy: 0.3958 - val_loss: 1.9715\n",
      "Epoch 12/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4045 - loss: 1.9084 - val_accuracy: 0.5069 - val_loss: 1.8144\n",
      "Epoch 13/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4547 - loss: 1.6746 - val_accuracy: 0.4861 - val_loss: 1.7938\n",
      "Epoch 14/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5067 - loss: 1.6707 - val_accuracy: 0.5174 - val_loss: 1.6244\n",
      "Epoch 15/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5211 - loss: 1.5160 - val_accuracy: 0.5486 - val_loss: 1.5800\n",
      "Epoch 16/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5424 - loss: 1.4408 - val_accuracy: 0.5625 - val_loss: 1.5001\n",
      "Epoch 17/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5540 - loss: 1.3751 - val_accuracy: 0.5521 - val_loss: 1.4853\n",
      "Epoch 18/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5933 - loss: 1.3150 - val_accuracy: 0.5590 - val_loss: 1.4369\n",
      "Epoch 19/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6122 - loss: 1.2390 - val_accuracy: 0.6215 - val_loss: 1.3398\n",
      "Epoch 20/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.6567 - loss: 1.1025 - val_accuracy: 0.6354 - val_loss: 1.2726\n",
      "Epoch 21/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6537 - loss: 1.0737 - val_accuracy: 0.6354 - val_loss: 1.1922\n",
      "Epoch 22/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7105 - loss: 0.9458 - val_accuracy: 0.6632 - val_loss: 1.2218\n",
      "Epoch 23/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6765 - loss: 0.9625 - val_accuracy: 0.6042 - val_loss: 1.3016\n",
      "Epoch 24/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6915 - loss: 0.9798 - val_accuracy: 0.6632 - val_loss: 1.0911\n",
      "Epoch 25/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7089 - loss: 0.9084 - val_accuracy: 0.6250 - val_loss: 1.1347\n",
      "Epoch 26/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7518 - loss: 0.8312 - val_accuracy: 0.6667 - val_loss: 1.0994\n",
      "Epoch 27/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7489 - loss: 0.8141 - val_accuracy: 0.6944 - val_loss: 1.0090\n",
      "Epoch 28/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7754 - loss: 0.7053 - val_accuracy: 0.6875 - val_loss: 1.0613\n",
      "Epoch 29/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7854 - loss: 0.6611 - val_accuracy: 0.6910 - val_loss: 0.9927\n",
      "Epoch 30/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7971 - loss: 0.6674 - val_accuracy: 0.6806 - val_loss: 0.9954\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=16, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f149f87d-031f-45b1-a7cb-5aabfc4e1634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8086 - loss: 0.6259 - val_accuracy: 0.6875 - val_loss: 1.0687\n",
      "Epoch 2/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8082 - loss: 0.5936 - val_accuracy: 0.6840 - val_loss: 1.0283\n",
      "Epoch 3/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8230 - loss: 0.5539 - val_accuracy: 0.7396 - val_loss: 0.9119\n",
      "Epoch 4/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8293 - loss: 0.5226 - val_accuracy: 0.7465 - val_loss: 0.9506\n",
      "Epoch 5/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8391 - loss: 0.5249 - val_accuracy: 0.7604 - val_loss: 0.8990\n",
      "Epoch 6/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8237 - loss: 0.5466 - val_accuracy: 0.7153 - val_loss: 1.0056\n",
      "Epoch 7/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8465 - loss: 0.4764 - val_accuracy: 0.7049 - val_loss: 1.1214\n",
      "Epoch 8/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8244 - loss: 0.5529 - val_accuracy: 0.7222 - val_loss: 1.0220\n",
      "Epoch 9/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8694 - loss: 0.4052 - val_accuracy: 0.7153 - val_loss: 0.9282\n",
      "Epoch 10/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8812 - loss: 0.3908 - val_accuracy: 0.7396 - val_loss: 0.9739\n",
      "Epoch 11/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8810 - loss: 0.3911 - val_accuracy: 0.7257 - val_loss: 1.0061\n",
      "Epoch 12/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8904 - loss: 0.3922 - val_accuracy: 0.7222 - val_loss: 0.9426\n",
      "Epoch 13/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8876 - loss: 0.3514 - val_accuracy: 0.7500 - val_loss: 0.8973\n",
      "Epoch 14/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9015 - loss: 0.2965 - val_accuracy: 0.7396 - val_loss: 1.0285\n",
      "Epoch 15/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8905 - loss: 0.3371 - val_accuracy: 0.7465 - val_loss: 0.9559\n",
      "Epoch 16/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8978 - loss: 0.2888 - val_accuracy: 0.7708 - val_loss: 0.9379\n",
      "Epoch 17/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9039 - loss: 0.3138 - val_accuracy: 0.7361 - val_loss: 0.9639\n",
      "Epoch 18/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9075 - loss: 0.2809 - val_accuracy: 0.7153 - val_loss: 0.9522\n",
      "Epoch 19/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8826 - loss: 0.3365 - val_accuracy: 0.7500 - val_loss: 0.9139\n",
      "Epoch 20/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9325 - loss: 0.2352 - val_accuracy: 0.7535 - val_loss: 0.9321\n",
      "Epoch 21/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9396 - loss: 0.2016 - val_accuracy: 0.7708 - val_loss: 0.9421\n",
      "Epoch 22/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9230 - loss: 0.2536 - val_accuracy: 0.7674 - val_loss: 0.8773\n",
      "Epoch 23/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9237 - loss: 0.2373 - val_accuracy: 0.7708 - val_loss: 0.8525\n",
      "Epoch 24/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9468 - loss: 0.2005 - val_accuracy: 0.7118 - val_loss: 0.9956\n",
      "Epoch 25/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9339 - loss: 0.2458 - val_accuracy: 0.7569 - val_loss: 0.9350\n",
      "Epoch 26/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9419 - loss: 0.2057 - val_accuracy: 0.7639 - val_loss: 0.9361\n",
      "Epoch 27/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9349 - loss: 0.2040 - val_accuracy: 0.7569 - val_loss: 1.0319\n",
      "Epoch 28/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9435 - loss: 0.1773 - val_accuracy: 0.7569 - val_loss: 0.9208\n",
      "Epoch 29/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9463 - loss: 0.1671 - val_accuracy: 0.7847 - val_loss: 1.0187\n",
      "Epoch 30/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9507 - loss: 0.1625 - val_accuracy: 0.7708 - val_loss: 0.9574\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=16, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8751dbf-8cac-4884-aadd-ce0deff66610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Actor_01       0.73      0.73      0.73        11\n",
      "    Actor_02       0.71      0.77      0.74        13\n",
      "    Actor_03       0.83      0.83      0.83         6\n",
      "    Actor_04       0.62      0.83      0.71        12\n",
      "    Actor_05       0.73      0.57      0.64        14\n",
      "    Actor_06       0.73      0.67      0.70        12\n",
      "    Actor_07       0.67      0.86      0.75        14\n",
      "    Actor_08       0.80      0.89      0.84         9\n",
      "    Actor_09       0.69      0.90      0.78        10\n",
      "    Actor_10       1.00      0.44      0.61        16\n",
      "    Actor_11       1.00      0.94      0.97        16\n",
      "    Actor_12       0.77      1.00      0.87        10\n",
      "    Actor_13       0.67      0.92      0.77        13\n",
      "    Actor_14       0.73      0.67      0.70        12\n",
      "    Actor_15       1.00      0.83      0.91        12\n",
      "    Actor_16       0.93      0.93      0.93        15\n",
      "    Actor_17       0.82      0.90      0.86        10\n",
      "    Actor_18       0.80      0.67      0.73        12\n",
      "    Actor_19       0.86      0.46      0.60        13\n",
      "    Actor_20       0.38      0.50      0.43        10\n",
      "    Actor_21       0.90      0.82      0.86        11\n",
      "    Actor_22       0.75      0.90      0.82        10\n",
      "    Actor_23       0.83      1.00      0.91        10\n",
      "    Actor_24       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.77       288\n",
      "   macro avg       0.78      0.78      0.77       288\n",
      "weighted avg       0.79      0.77      0.77       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_labels, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a05998d-7ce2-4144-80a7-55cb33e373ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9505208134651184\n",
      "Validation Accuracy: 0.7708333134651184\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy:\", history.history['accuracy'][-1])\n",
    "print(\"Validation Accuracy:\", history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0c88475-e0f2-464d-8368-81074ffb30e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('../model/speech_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b22755d-a37d-42f6-bfc8-1e1492efdbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved!\n"
     ]
    }
   ],
   "source": [
    "# Save training history\n",
    "with open('../model/speech_model_history.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n",
    "\n",
    "print(\"Model training complete and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451218fb-7b90-425d-ac1e-eabf21fccfac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
